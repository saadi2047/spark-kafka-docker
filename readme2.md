README.md â€” Spark-Kafka-MySQL ETL with Airflow + Loki/Grafana
# ğŸš€ Spark-Kafka-MySQL ETL Pipeline  
### with Apache Airflow + Loki/Promtail + Grafana  
*(E-PAY 2.0 POC for SBI Ã— Red Hat)*

![Spark](https://img.shields.io/badge/Apache%20Spark-4.0.0-FF7F50?logo=apache-spark&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-3.7.0-black?logo=apache-kafka&logoColor=white)
![MySQL](https://img.shields.io/badge/MySQL-8.0.43-4479A1?logo=mysql&logoColor=white)
![Airflow](https://img.shields.io/badge/Apache%20Airflow-2.10.2-017CEE?logo=apache-airflow&logoColor=white)
![Grafana](https://img.shields.io/badge/Grafana-11.1.0-F46800?logo=grafana&logoColor=white)
![Loki](https://img.shields.io/badge/Loki-3.0.0-00BFFF?logo=grafana&logoColor=white)
![Promtail](https://img.shields.io/badge/Promtail-3.0.0-00BFFF?logo=grafana&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-Compose-blue?logo=docker&logoColor=white)
![License](https://img.shields.io/badge/License-MIT-green)

---

### ğŸ§  **About**

This repository provides a **complete end-to-end containerized data engineering environment** featuring:

- **Apache Spark** for batch ETL and comparison jobs  
- **Kafka (KRaft mode)** for real-time data streaming  
- **MySQL** as both the source and sink  
- **Apache Airflow** for job orchestration  
- **Grafana Loki + Promtail** for centralized log aggregation and visualization  

Built and optimized as part of the **E-PAY 2.0 modern banking pipeline** (State Bank of India Ã— Red Hat).

---

## ğŸ—ï¸ **Architecture**


           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚         Apache Airflow         â”‚
           â”‚   (Job Orchestrator & DAG UI)  â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚ triggers
                          â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                 Apache Spark                 â”‚
    â”‚  spark-master + spark-worker + history-serverâ”‚
    â”‚  runs ETL jobs via JDBC over MySQL           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
             â”‚    MySQL     â”‚
             â”‚ Source+Sink  â”‚
             â”‚ table1/table2â”‚
             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚   Apache Kafka     â”‚
           â”‚   (KRaft broker)   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚
                   â–¼
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚ Loki + Promtail + Grafana UI â”‚
           â”‚ Centralized log monitoring   â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜


---

## ğŸ§° **Tech Stack**

| Component | Role |
|------------|------|
| **Apache Spark 4.0.0** | ETL & table comparison engine |
| **Apache Kafka 3.7.0 (KRaft)** | Messaging backbone (no Zookeeper) |
| **MySQL 8.0.43** | Source & sink DB |
| **Apache Airflow 2.10.2** | DAG orchestration & scheduler |
| **Grafana + Loki + Promtail** | Observability & log analytics |
| **Docker Compose** | Local orchestration of multi-service stack |

---

## âš™ï¸ **1ï¸âƒ£ Prerequisites**

- Docker â‰¥ 24.x  
- Docker Compose â‰¥ 2.x  
- â‰¥ 8 GB RAM (recommended 12 GB)  
- Linux or WSL 2 environment

---

## ğŸ“ **2ï¸âƒ£ Repository Structure**



spark-kafka-docker/
â”œâ”€â”€ airflow/
â”‚ â”œâ”€â”€ dags/
â”‚ â”‚ â”œâ”€â”€ compare_tables_dag.py
â”‚ â”‚ â””â”€â”€ spark_kafka_mysql_dag.py
â”‚ â”œâ”€â”€ logs/
â”‚ â””â”€â”€ plugins/
â”‚
â”œâ”€â”€ loki/config.yaml
â”œâ”€â”€ promtail/config.yml
â”œâ”€â”€ table_compare_etl.py
â”‚
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ docker-compose.airflow.yml
â”œâ”€â”€ docker-compose.loki.yml
â”œâ”€â”€ jars/
â”œâ”€â”€ logs/
â””â”€â”€ README.md


---

## ğŸ³ **3ï¸âƒ£ Deployment Steps**

### ğŸ§© Step 1 â€“ Start Core Stack
```bash
docker-compose up -d

â˜ï¸ Step 2 â€“ Start Airflow
docker-compose -f docker-compose.airflow.yml up -d

ğŸ“Š Step 3 â€“ Start Loki + Promtail + Grafana
docker-compose -f docker-compose.loki.yml up -d


Check:

docker ps --format "table {{.Names}}\t{{.Status}}\t{{.Ports}}"

ğŸ’¾ 4ï¸âƒ£ Database Initialization
docker exec -it mysql mysql -usparkuser -psparkpass testdb

CREATE TABLE table1 (id INT, name VARCHAR(50), amount INT);
CREATE TABLE table2 (id INT, name VARCHAR(50), amount INT);
CREATE TABLE table_compare_result AS SELECT * FROM table1 WHERE 1=0;

INSERT INTO table1 VALUES (1,'Alice',100),(2,'Bob',200),(3,'Charlie',300);
INSERT INTO table2 VALUES (1,'Alice',100),(2,'Bob',250),(3,'Charlie',300);

âš¡ 5ï¸âƒ£ ETL Script: Table Comparison

table_compare_etl.py runs Spark ETL to:

Read table1 and table2

Compare records and detect mismatches

Write output to table_compare_result

Manual run:

docker exec -it spark-master \
  spark-submit \
  --master spark://spark-master:7077 \
  --jars /opt/spark/jars/mysql-connector-java-8.0.33.jar \
  /opt/spark/work-dir/table_compare_etl.py

ğŸª¶ 6ï¸âƒ£ Airflow Orchestration

Web UI â†’ http://localhost:8080

Username: adminâ€ƒâ€ƒPassword: admin

Enable & trigger compare_tables_dag
or via CLI:

docker exec airflow-scheduler airflow dags trigger compare_tables_dag
docker exec airflow-scheduler airflow dags list-runs -d compare_tables_dag

ğŸ“ˆ 7ï¸âƒ£ Logs & Monitoring

Grafana â†’ http://localhost:3000

Username: adminâ€ƒPassword: admin

Loki endpoint: http://loki:3100

Query examples:

{container_name="spark-master"}
{container_name="airflow-webserver"}

ğŸ§  8ï¸âƒ£ Validate Output
docker exec -it mysql mysql -usparkuser -psparkpass testdb
SELECT * FROM table_compare_result;


Expected result:

id_a	name_a	amount_a	id_b	name_b	amount_b
2	Bob	200	2	Bob	250
ğŸ›  9ï¸âƒ£ Handy Commands
Action	Command
Rebuild all	docker-compose down -v && docker-compose up -d
View logs	docker logs spark-master -f
Restart Airflow	docker-compose -f docker-compose.airflow.yml restart
Stop all	docker-compose down && docker-compose -f docker-compose.airflow.yml down && docker-compose -f docker-compose.loki.yml down
ğŸš€ ğŸ”Ÿ Next Enhancements

Add Kafka â†’ Spark streaming DAG (CDC)

Push ETL metadata to S3/DynamoDB

Integrate Service Mesh (Kiali/Istio)

Create Grafana dashboard JSONs

Add email alerts from Airflow for ETL status

ğŸ‘¨â€ğŸ’» Author

Saadi Muzzammil
DevOps & Data Engineering â€” E-PAY 2.0 (SBI Ã— Red Hat)
ğŸ“¦ GitHub: saadi2047

ğŸªª License

MIT License Â© 2025 Saadi Muzzammil


---

### âœ… Next Recommendation
Once you add this file:
```bash
mv README.md README_with_badges.md
mv README_with_badges.md README.md
git add README.md
git commit -m "Added badge-style README with full documentation"
git push origin main
