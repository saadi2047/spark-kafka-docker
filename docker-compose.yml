version: '3.8'

services:
  # -------------------------
  # ğŸ§© Kafka (KRaft mode)
  # -------------------------
  kafka:
    image: apache/kafka:3.7.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      # Basic Kafka node configuration
      - KAFKA_NODE_ID=1
      - KAFKA_PROCESS_ROLES=broker,controller

      # Listeners: internal for controller + external for clients
      - KAFKA_LISTENERS=PLAINTEXT://:9092,CONTROLLER://:9093
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://kafka:9092   # for inter-container access
      - KAFKA_CONTROLLER_LISTENER_NAMES=CONTROLLER
      - KAFKA_CONTROLLER_QUORUM_VOTERS=1@kafka:9093

      # Log storage
      - KAFKA_LOG_DIRS=/tmp/kraft-combined-logs

      # Single-node safety
      - KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR=1
      - KAFKA_TRANSACTION_STATE_LOG_MIN_ISR=1
      - KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS=0
    networks:
      - sparknet

  # -------------------------
  # ğŸ›  Kafka Tools (CLI shell)
  # -------------------------
  kafka-tools:
    image: confluentinc/cp-kafka:7.7.0
    container_name: kafka-tools
    depends_on:
      - kafka
    entrypoint: ["sleep", "infinity"]
    networks:
      - sparknet

  # -------------------------
  # âš¡ Spark Master
  # -------------------------
  spark-master:
    image: saadimm/spark:4.0.0-aws
    container_name: spark-master
    ports:
      - "8081:8080"   # Spark Master UI
      - "7077:7077"   # Spark cluster port
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
      --host spark-master
    networks:
      - sparknet
    volumes:
      - spark_events:/spark-events

  # -------------------------
  # âš™ï¸ Spark Worker
  # -------------------------
  spark-worker:
    image: saadimm/spark:4.0.0-aws
    container_name: spark-worker
    depends_on:
      - spark-master
    ports:
      - "8082:8081"   # Spark Worker UI (unique port)
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker
      spark://spark-master:7077
    networks:
      - sparknet
    volumes:
      - spark_events:/spark-events

  # -------------------------
  # ğŸ“œ Spark History Server
  # -------------------------
  spark-history-server:
    image: saadimm/spark:4.0.0-aws
    container_name: spark-history-server
    depends_on:
      - spark-master
    ports:
      - "18080:18080"   # History Server UI
    command: >
      /opt/spark/bin/spark-class org.apache.spark.deploy.history.HistoryServer
    environment:
      SPARK_HISTORY_OPTS: >
        -Dspark.history.fs.logDirectory=/spark-events
        -Dspark.history.fs.cleaner.enabled=true
        -Dspark.history.fs.cleaner.interval=1h
        -Dspark.history.fs.cleaner.maxAge=12h
    volumes:
      - spark_events:/spark-events
    networks:
      - sparknet

  # -------------------------
  # ğŸ—„ï¸ MySQL Database
  # -------------------------
  mysql:
    image: mysql:8.0.43
    container_name: mysql
    restart: always
    environment:
      MYSQL_ROOT_PASSWORD: root
      MYSQL_DATABASE: testdb
      MYSQL_USER: sparkuser
      MYSQL_PASSWORD: sparkpass
    ports:
      - "3307:3306"     # avoid conflict with any local MySQL
    volumes:
      - mysql_data:/var/lib/mysql
    networks:
      - sparknet

# -------------------------
# ğŸŒ Shared Network & Volumes
# -------------------------
networks:
  sparknet:
    driver: bridge

volumes:
  mysql_data:
  spark_events:

